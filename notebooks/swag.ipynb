{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76987774-7d7a-4bd2-a0ac-a9abaf6d5c7e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c61db724-c905-4458-a58f-d3cab189b8b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import operator\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../src\") if \"../src\" not in sys.path else None \n",
    "\n",
    "# custom imports\n",
    "from methods import *\n",
    "from GenericDNN import GenericDNN\n",
    "from swag import train_swag, inference_swag, sample_posterior_swag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705e4fe4-9ab3-410f-b7e4-30637a0e0cf0",
   "metadata": {},
   "source": [
    "### Initialize Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "268c1570-90c6-4c4c-9f65-a5e6e9c7eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose dataset to use\n",
    "dataset_name = 'yacht.txt'\n",
    "datasets_path = '../datasets/'\n",
    "dataset_path = datasets_path + dataset_name\n",
    "\n",
    "# load data and create torch training data loader\n",
    "(X_train, y_train), (X_test, y_test) = load_data(dataset_path)\n",
    "trainloader = torch.utils.data.DataLoader(Dataset(X_train, y_train, dataset_name.split('.')[0]), \n",
    "                                         batch_size:=32, shuffle:=True)\n",
    "\n",
    "# init model, criterion and optimizer\n",
    "net = GenericDNN(input_size:=X_train.shape[-1], hidden_size:=input_size, output_size:=1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e73d18-b356-4f58-ab32-1d117a8c67d6",
   "metadata": {},
   "source": [
    "### Choose whether to train weights (SWAG), and do inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6fc5f558-a9be-472e-80d7-94ac3d7b3daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'train:=True' if model not previously trained, or want to train a new model\n",
    "checkpoint_path = '../checkpoints/'\n",
    "if train:=False:\n",
    "    # delete previous checkpoints for model with current dataset\n",
    "    onlyfiles = [f for f in os.listdir(checkpoint_path) if os.path.isfile(os.path.join(checkpoint_path, f))]\n",
    "    for file in onlyfiles:\n",
    "        if trainloader.dataset.name in file:\n",
    "            print(f\"Deletes {file=}\")\n",
    "            os.remove(checkpoint_path + file)\n",
    "    \n",
    "    # train and save weights\n",
    "    train_swag(\n",
    "        net,\n",
    "        trainloader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        init_epochs=1000,\n",
    "        sampling_epochs=5,\n",
    "        nsamples=200,\n",
    "        path_to_checkpoints=\"../checkpoints/\",\n",
    "    )\n",
    "\n",
    "# Do inference (infer approximate sample mean and covariance of an assumed Guassian posterior)\n",
    "theta_SWA, cov_diag, D = inference_swag(trainloader.dataset.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1b06d-2251-4262-a33f-05b0f68d858b",
   "metadata": {},
   "source": [
    "### Try to sample some weights from the posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e7346a45-5670-4d11-b144-8717459aba5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[-0.1999, -0.0791,  0.3942, -0.4994, -0.6365, -0.2056],\n",
       "                      [-0.1365, -0.0495,  0.2243, -0.3310, -0.3824, -0.3242],\n",
       "                      [ 0.3466,  0.2380, -0.4285,  0.3731,  0.5174,  1.6986],\n",
       "                      [-0.2017, -0.2345,  0.4336, -0.1760, -0.3615, -0.5294],\n",
       "                      [-0.2059, -0.0492,  0.0940,  0.0714, -0.0346, -2.1599],\n",
       "                      [-0.0414,  0.0753, -0.2142,  0.3107,  0.2652, -2.5509]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.4519,  0.6594, -0.7872,  1.3513,  0.9575,  2.7161])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.6573, -0.7069,  1.4609, -1.4453, -1.7629,  3.0561]])),\n",
       "             ('fc2.bias', tensor([-3.6144]))])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample weights from the inferred approximate posterior distribution\n",
    "\n",
    "# ----\n",
    "# The beauty of this approach is that the returned weight-sample can\n",
    "# be directly loaded into the model. i.e. by:\n",
    "# 'net.load_state_dict(sample_posterior_swag(theta_SWA, cov_diag, D))'\n",
    "# ----\n",
    "sample_posterior_swag(theta_SWA, cov_diag, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "958ac644-633f-49a9-9cd0-13b4ef580b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(sample_posterior_swag(theta_SWA, cov_diag, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53353d-0100-486c-b0f2-5c53ae25b8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
